{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPPT Dataset Analysis Examples\n",
    "\n",
    "This notebook demonstrates how to analyze the OPPT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install datasets pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"Open-Privacy-Policy-Taxonomy/oppt-privacy-policies\")\n",
    "print(f\"Loaded {len(dataset['train'])} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = Counter(dataset[\"train\"][\"primary_category\"])\n",
    "\n",
    "print(\"Category Distribution:\")\n",
    "print(\"-\" * 40)\n",
    "for cat, count in categories.most_common():\n",
    "    pct = count / len(dataset[\"train\"]) * 100\n",
    "    print(f\"{cat:25} {count:5} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = Counter(dataset[\"train\"][\"category_consensus_type\"])\n",
    "\n",
    "print(\"Consensus Types:\")\n",
    "print(\"-\" * 40)\n",
    "for ct, count in consensus.most_common():\n",
    "    pct = count / len(dataset[\"train\"]) * 100\n",
    "    print(f\"{ct:25} {count:5} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_counts = Counter(dataset[\"train\"][\"company\"])\n",
    "\n",
    "print(f\"Total companies: {len(company_counts)}\")\n",
    "print(f\"\\nTop 10 by segment count:\")\n",
    "print(\"-\" * 40)\n",
    "for company, count in company_counts.most_common(10):\n",
    "    print(f\"{company:25} {count:5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Jurisdiction-Siloed Disclosures\n",
    "\n",
    "Look for substantive categories appearing in REGIONAL sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories that should be universal, not hidden in regional sections\n",
    "substantive_categories = {\n",
    "    \"FIRST_PARTY\", \"THIRD_PARTY\", \"SALE_SHARING\", \n",
    "    \"AUTOMATED_DECISIONS\", \"SENSITIVE_DATA\", \"TRACKING\"\n",
    "}\n",
    "\n",
    "# Find REGIONAL segments\n",
    "regional_segments = dataset[\"train\"].filter(\n",
    "    lambda x: x[\"primary_category\"] == \"REGIONAL\"\n",
    ")\n",
    "\n",
    "print(f\"REGIONAL segments: {len(regional_segments)}\")\n",
    "\n",
    "# Check secondary categories for substantive content\n",
    "siloed_count = 0\n",
    "for segment in regional_segments:\n",
    "    secondary = json.loads(segment[\"secondary_categories\"]) if segment[\"secondary_categories\"] else []\n",
    "    if any(cat in substantive_categories for cat in secondary):\n",
    "        siloed_count += 1\n",
    "\n",
    "print(f\"REGIONAL segments with substantive secondary categories: {siloed_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all data types mentioned in FIRST_PARTY segments\n",
    "data_types = Counter()\n",
    "\n",
    "for segment in dataset[\"train\"]:\n",
    "    if segment[\"primary_category\"] == \"FIRST_PARTY\":\n",
    "        attrs = json.loads(segment[\"attributes_annotator_1\"])\n",
    "        if \"FIRST_PARTY\" in attrs:\n",
    "            for dt in attrs[\"FIRST_PARTY\"].get(\"personal_information_type\", []):\n",
    "                data_types[dt] += 1\n",
    "\n",
    "print(\"Data types collected (FIRST_PARTY segments):\")\n",
    "print(\"-\" * 40)\n",
    "for dt, count in data_types.most_common(15):\n",
    "    print(f\"{dt:35} {count:5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for more analysis options\n",
    "import pandas as pd\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV if needed\n",
    "# df.to_csv(\"oppt_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
